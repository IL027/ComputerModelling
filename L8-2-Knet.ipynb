{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    " * AutoGrad\n",
    " * Logistic Regression revisited\n",
    " * Multiclass logistic regression\n",
    " * Multilayer Neural Networks and Deeplearning\n",
    " \n",
    "closely following [Knet-the-Julia-dope](https://github.com/moralesq/Knet-the-Julia-dope) in turn based on [Deep Learning - The Straight Dope](http://gluon.mxnet.io/) using MXNet which can also be accessed from Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Introduction\n",
    "Typically gradients in neural network are computed using back-propagation. An alternative is to use autograd.  This is the approach taken by the popular [autograd](https://github.com/HIPS/autograd) Python package and its Julia port AutoGrad.jl used by Knet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AutoGrad\n",
    "using Knet, Plots, DataFrames\n",
    "gr()\n",
    "using Suppressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a toy example:  $f = 2x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x    = [1 2; 3 4];\n",
    "f(x) = 2x^2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Knet g=grad(f) generates a gradient function g, which takes the same inputs as the function f but returns the gradient. The gradient function g triggers recording by boxing the parameters in a special data type and calls f. The elementary operations in f are overloaded to record their actions and output boxed answers when their inputs are boxed. The sequence of recorded operations is then used to compute gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = grad(f)\n",
    "g(5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# (Stochastic) Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimize $f$ we consider the recursion:\n",
    "$$ x_{n+1}=x_{n}-\\epsilon \\nabla f(x_n)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 600 400\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip6700\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"600\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6700)\" points=\"\n",
       "0,400 600,400 600,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6701\">\n",
       "    <rect x=\"120\" y=\"0\" width=\"421\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6700)\" points=\"\n",
       "48.2225,360.121 580.315,360.121 580.315,11.811 48.2225,11.811 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6702\">\n",
       "    <rect x=\"48\" y=\"11\" width=\"533\" height=\"349\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  150.341,360.121 150.341,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  257.835,360.121 257.835,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  365.328,360.121 365.328,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  472.822,360.121 472.822,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  580.315,360.121 580.315,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,305.697 580.315,305.697 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,251.274 580.315,251.274 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,196.851 580.315,196.851 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,142.427 580.315,142.427 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,88.0038 580.315,88.0038 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,33.5804 580.315,33.5804 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,360.121 580.315,360.121 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,360.121 48.2225,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  150.341,360.121 150.341,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.835,360.121 257.835,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  365.328,360.121 365.328,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  472.822,360.121 472.822,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  580.315,360.121 580.315,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,305.697 56.2039,305.697 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,251.274 56.2039,251.274 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,196.851 56.2039,196.851 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,142.427 56.2039,142.427 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,88.0038 56.2039,88.0038 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,33.5804 56.2039,33.5804 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 150.341, 373.921)\" x=\"150.341\" y=\"373.921\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 257.835, 373.921)\" x=\"257.835\" y=\"373.921\">40</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 365.328, 373.921)\" x=\"365.328\" y=\"373.921\">60</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 472.822, 373.921)\" x=\"472.822\" y=\"373.921\">80</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 580.315, 373.921)\" x=\"580.315\" y=\"373.921\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 42.2225, 310.197)\" x=\"42.2225\" y=\"310.197\">0.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 42.2225, 255.774)\" x=\"42.2225\" y=\"255.774\">1.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 42.2225, 201.351)\" x=\"42.2225\" y=\"201.351\">1.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 42.2225, 146.927)\" x=\"42.2225\" y=\"146.927\">2.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 42.2225, 92.5038)\" x=\"42.2225\" y=\"92.5038\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 42.2225, 38.0804)\" x=\"42.2225\" y=\"38.0804\">3.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:16; text-anchor:middle;\" transform=\"rotate(0, 314.269, 397.6)\" x=\"314.269\" y=\"397.6\">steps</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:16; text-anchor:middle;\" transform=\"rotate(-90, 14.4, 185.966)\" x=\"14.4\" y=\"185.966\">x</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6702)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,11.811 53.5972,81.4729 58.9719,137.202 64.3465,181.786 69.7212,217.453 75.0959,245.987 80.4706,268.813 85.8452,287.075 91.2199,301.684 96.5946,313.371 \n",
       "  101.969,322.721 107.344,330.201 112.719,336.185 118.093,340.972 123.468,344.802 128.843,347.866 134.217,350.317 139.592,352.277 144.967,353.846 150.341,355.101 \n",
       "  155.716,356.105 161.091,356.908 166.465,357.551 171.84,358.065 177.215,358.476 182.589,358.805 187.964,359.068 193.339,359.278 198.713,359.447 204.088,359.582 \n",
       "  209.463,359.689 214.837,359.776 220.212,359.845 225.587,359.9 230.961,359.944 236.336,359.979 241.711,360.008 247.085,360.03 252.46,360.048 257.835,360.063 \n",
       "  263.209,360.074 268.584,360.084 273.959,360.091 279.333,360.097 284.708,360.102 290.083,360.105 295.457,360.109 300.832,360.111 306.207,360.113 311.581,360.114 \n",
       "  316.956,360.116 322.331,360.117 327.705,360.117 333.08,360.118 338.455,360.119 343.829,360.119 349.204,360.119 354.579,360.12 359.953,360.12 365.328,360.12 \n",
       "  370.703,360.12 376.077,360.12 381.452,360.12 386.827,360.12 392.201,360.12 397.576,360.12 402.951,360.121 408.325,360.121 413.7,360.121 419.075,360.121 \n",
       "  424.449,360.121 429.824,360.121 435.199,360.121 440.574,360.121 445.948,360.121 451.323,360.121 456.698,360.121 462.072,360.121 467.447,360.121 472.822,360.121 \n",
       "  478.196,360.121 483.571,360.121 488.946,360.121 494.32,360.121 499.695,360.121 505.07,360.121 510.444,360.121 515.819,360.121 521.194,360.121 526.568,360.121 \n",
       "  531.943,360.121 537.318,360.121 542.692,360.121 548.067,360.121 553.442,360.121 558.816,360.121 564.191,360.121 569.566,360.121 574.94,360.121 580.315,360.121 \n",
       "  \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip6700)\" points=\"\n",
       "489.608,62.931 562.315,62.931 562.315,32.691 489.608,32.691 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  489.608,62.931 562.315,62.931 562.315,32.691 489.608,32.691 489.608,62.931 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6700)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  495.608,47.811 531.608,47.811 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:start;\" transform=\"rotate(0, 537.608, 52.311)\" x=\"537.608\" y=\"52.311\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "xs=Float64[]\n",
    "lr=0.05\n",
    "x=4.0\n",
    "for i=1:100\n",
    "    x-=lr *g(x)\n",
    "    push!(xs,x)\n",
    "end\n",
    "plot([1:100;],xs); ylabel!(\"x\");xlabel!(\"steps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# (Stochastic) Gradient Descent\n",
    "In order to minimize $f$ we consider the recursion:\n",
    "$$ x_{n+1}=x_{n}-\\epsilon \\widehat{\\nabla f}_n(x_n)$$\n",
    "where  $\\mathbb{E}\\widehat{\\nabla f}_n(x)=\\nabla f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 600 400\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip6900\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"600\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6900)\" points=\"\n",
       "0,400 600,400 600,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6901\">\n",
       "    <rect x=\"120\" y=\"0\" width=\"421\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6900)\" points=\"\n",
       "38.1866,360.121 580.315,360.121 580.315,11.811 38.1866,11.811 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6902\">\n",
       "    <rect x=\"38\" y=\"11\" width=\"543\" height=\"349\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  142.231,360.121 142.231,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  251.752,360.121 251.752,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  361.273,360.121 361.273,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  470.794,360.121 470.794,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  580.315,360.121 580.315,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  38.1866,337.638 580.315,337.638 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  38.1866,236.018 580.315,236.018 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  38.1866,134.399 580.315,134.399 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  38.1866,32.7794 580.315,32.7794 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,360.121 580.315,360.121 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,360.121 38.1866,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  142.231,360.121 142.231,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  251.752,360.121 251.752,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  361.273,360.121 361.273,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  470.794,360.121 470.794,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  580.315,360.121 580.315,354.896 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,337.638 46.3186,337.638 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,236.018 46.3186,236.018 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,134.399 46.3186,134.399 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,32.7794 46.3186,32.7794 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 142.231, 373.921)\" x=\"142.231\" y=\"373.921\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 251.752, 373.921)\" x=\"251.752\" y=\"373.921\">40</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 361.273, 373.921)\" x=\"361.273\" y=\"373.921\">60</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 470.794, 373.921)\" x=\"470.794\" y=\"373.921\">80</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 580.315, 373.921)\" x=\"580.315\" y=\"373.921\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 32.1866, 342.138)\" x=\"32.1866\" y=\"342.138\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 32.1866, 240.518)\" x=\"32.1866\" y=\"240.518\">1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 32.1866, 138.899)\" x=\"32.1866\" y=\"138.899\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 32.1866, 37.2794)\" x=\"32.1866\" y=\"37.2794\">3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:16; text-anchor:middle;\" transform=\"rotate(0, 309.251, 397.6)\" x=\"309.251\" y=\"397.6\">steps</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:16; text-anchor:middle;\" transform=\"rotate(-90, 14.4, 185.966)\" x=\"14.4\" y=\"185.966\">x</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6902)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  38.1866,11.811 43.6627,77.6861 49.1387,130.884 54.6148,160.627 60.0908,195.804 65.5669,231.973 71.0429,247.936 76.519,257.678 81.995,274.061 87.471,295.579 \n",
       "  92.9471,307.565 98.4231,317.963 103.899,314.091 109.375,308.387 114.851,323.378 120.327,323.575 125.803,319.909 131.279,320.794 136.755,323.433 142.231,324.677 \n",
       "  147.708,326.449 153.184,324.844 158.66,330.463 164.136,330.628 169.612,329.243 175.088,333.88 180.564,334.886 186.04,339.037 191.516,337.68 196.992,342.979 \n",
       "  202.468,350.12 207.944,348.306 213.42,348.364 218.896,345.088 224.372,344.466 229.848,337.545 235.324,340.045 240.8,333.88 246.276,342.744 251.752,349.551 \n",
       "  257.228,352.235 262.704,347.874 268.18,346.816 273.657,344.983 279.133,344.038 284.609,342.627 290.085,349.633 295.561,354.253 301.037,360.121 306.513,358.654 \n",
       "  311.989,351.572 317.465,358.646 322.941,341.79 328.417,340.391 333.893,347.33 339.369,343.087 344.845,336.554 350.321,333.66 355.797,332.544 361.273,337.513 \n",
       "  366.749,329.146 372.225,333.609 377.701,334.582 383.177,332.569 388.653,330.226 394.129,336.852 399.606,337.888 405.082,338.742 410.558,342.987 416.034,338.346 \n",
       "  421.51,331.828 426.986,333.15 432.462,334.937 437.938,331.019 443.414,334.501 448.89,326.799 454.366,338.246 459.842,339.783 465.318,337.96 470.794,343.601 \n",
       "  476.27,349.203 481.746,353.187 487.222,345.658 492.698,339.078 498.174,338.414 503.65,332.472 509.126,337.715 514.602,346.759 520.078,343.988 525.555,340.931 \n",
       "  531.031,342.426 536.507,338.546 541.983,339.754 547.459,343.96 552.935,337.957 558.411,337.665 563.887,339.017 569.363,339.561 574.839,334.387 580.315,337.739 \n",
       "  \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip6900)\" points=\"\n",
       "489.608,62.931 562.315,62.931 562.315,32.691 489.608,32.691 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  489.608,62.931 562.315,62.931 562.315,32.691 489.608,32.691 489.608,62.931 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6900)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  495.608,47.811 531.608,47.811 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6900)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:start;\" transform=\"rotate(0, 537.608, 52.311)\" x=\"537.608\" y=\"52.311\">y1</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "xs=Float64[]\n",
    "lr=0.05\n",
    "x=4.0\n",
    "for i=1:100\n",
    "    x-=lr *(g(x)+randn())\n",
    "    push!(xs,x)\n",
    "end\n",
    "plot([1:100;],xs)\n",
    "ylabel!(\"x\");xlabel!(\"steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Binary classification with logistic regression\n",
    "\n",
    "\n",
    "The simplest kind of classification problem is *binary classification*, when there are only two categories, so let's start there. Let's call our two categories the positive class $y_i=1$ and the negative class $y_i = 0$ (another common way of defining the labels are $y_i=\\pm1$). Even with just two categories, and even confining ourselves to linear models, \n",
    "there are many ways we might approach the problem. For example, we might try to draw a line that best separates the points:\n",
    "\n",
    "![](../img/linear-separator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall that in linear regression, we made predictions of the form\n",
    "\n",
    "$$ \\hat{y} = \\boldsymbol{w}^T \\boldsymbol{x} + b, $$\n",
    "\n",
    "where $\\hat{y},b\\in\\mathbb{R}$ and $\\boldsymbol{w},\\boldsymbol{x}\\in\\mathbb{R}^d$. We are interested in asking the question *\"what is the probability that example $\\boldsymbol{x}$ belongs to the positive class?\"* A regular linear model is a poor choice here because it can output values greater than $1$ or less than $0$. To coerce reasonable answers from our model,  we're going to modify it slightly, by running the linear function through a sigmoid activation function $\\sigma$:\n",
    "\n",
    "$$ \\hat{y} =\\sigma(\\boldsymbol{w}^T \\boldsymbol{x} + b). $$\n",
    "\n",
    "The sigmoid function $\\sigma$, sometimes called a squashing function or a *logistic* function - t- maps a real-valued input to the range 0 to 1. If we pick the labels $y\\in(0,1)$ we may assign  \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}(y=1|z) & =\\sigma(z)=\\frac{1}{1+e^{-z}}\\\\\n",
    "\\mathbb{P}(y=0|z) & =1-\\sigma(z)=\\frac{1}{1+e^{z}}\\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Compact form: $\\mathbb{P}(y|z)  =\\sigma(z)^y(1-\\sigma(z))^{1-y}$. Let us define and visualize this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"400\" height=\"200\" viewBox=\"0 0 400 200\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip7100\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"400\" height=\"200\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip7100)\" points=\"\n",
       "0,200 400,200 400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip7101\">\n",
       "    <rect x=\"80\" y=\"0\" width=\"281\" height=\"200\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip7100)\" points=\"\n",
       "48.2225,160.121 380.315,160.121 380.315,31.4961 48.2225,31.4961 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip7102\">\n",
       "    <rect x=\"48\" y=\"31\" width=\"333\" height=\"130\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,160.121 48.2225,31.4961 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  131.246,160.121 131.246,31.4961 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  214.269,160.121 214.269,31.4961 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  297.292,160.121 297.292,31.4961 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  380.315,160.121 380.315,31.4961 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,134.919 380.315,134.919 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,108.845 380.315,108.845 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,82.7714 380.315,82.7714 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  48.2225,56.6975 380.315,56.6975 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,160.121 380.315,160.121 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,160.121 48.2225,31.4961 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,160.121 48.2225,158.191 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  131.246,160.121 131.246,158.191 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  214.269,160.121 214.269,158.191 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  297.292,160.121 297.292,158.191 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  380.315,160.121 380.315,158.191 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,134.919 53.2039,134.919 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,108.845 53.2039,108.845 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,82.7714 53.2039,82.7714 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip7100)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,56.6975 53.2039,56.6975 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 48.2225, 172.921)\" x=\"48.2225\" y=\"172.921\">-5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 131.246, 172.921)\" x=\"131.246\" y=\"172.921\">-2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 214.269, 172.921)\" x=\"214.269\" y=\"172.921\">0.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 297.292, 172.921)\" x=\"297.292\" y=\"172.921\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 380.315, 172.921)\" x=\"380.315\" y=\"172.921\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 44.2225, 139.419)\" x=\"44.2225\" y=\"139.419\">0.2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 44.2225, 113.345)\" x=\"44.2225\" y=\"113.345\">0.4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 44.2225, 87.2714)\" x=\"44.2225\" y=\"87.2714\">0.6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 44.2225, 61.1975)\" x=\"44.2225\" y=\"61.1975\">0.8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:21; text-anchor:middle;\" transform=\"rotate(0, 214.269, 18)\" x=\"214.269\" y=\"18\">Logistic Function</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:16; text-anchor:middle;\" transform=\"rotate(0, 214.269, 197.6)\" x=\"214.269\" y=\"197.6\">z</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7100)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:16; text-anchor:middle;\" transform=\"rotate(-90, 14.4, 95.8084)\" x=\"14.4\" y=\"95.8084\">sigmoid(z)</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip7102)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  48.2225,160.121 51.5434,160.03 54.8644,159.929 58.1853,159.818 61.5062,159.696 64.8271,159.561 68.1481,159.412 71.469,159.248 74.7899,159.067 78.1108,158.868 \n",
       "  81.4318,158.648 84.7527,158.407 88.0736,158.141 91.3945,157.848 94.7155,157.526 98.0364,157.172 101.357,156.783 104.678,156.356 107.999,155.887 111.32,155.373 \n",
       "  114.641,154.81 117.962,154.194 121.283,153.52 124.604,152.783 127.925,151.98 131.246,151.104 134.567,150.15 137.887,149.114 141.208,147.989 144.529,146.77 \n",
       "  147.85,145.453 151.171,144.031 154.492,142.5 157.813,140.856 161.134,139.093 164.455,137.21 167.776,135.204 171.097,133.073 174.418,130.816 177.739,128.435 \n",
       "  181.059,125.931 184.38,123.31 187.701,120.575 191.022,117.735 194.343,114.798 197.664,111.773 200.985,108.674 204.306,105.513 207.627,102.305 210.948,99.0649 \n",
       "  214.269,95.8084 217.59,92.5518 220.911,89.3115 224.232,86.1033 227.552,82.9425 230.873,79.8434 234.194,76.8192 237.515,73.8818 240.836,71.0414 244.157,68.3069 \n",
       "  247.478,65.6853 250.799,63.182 254.12,60.8009 257.441,58.5441 260.762,56.4127 264.083,54.4063 267.404,52.5232 270.724,50.7611 274.045,49.1166 277.366,47.5857 \n",
       "  280.687,46.164 284.008,44.8464 287.329,43.628 290.65,42.5032 293.971,41.4667 297.292,40.5131 300.613,39.6371 303.934,38.8333 307.255,38.0969 310.576,37.4228 \n",
       "  313.896,36.8064 317.217,36.2434 320.538,35.7295 323.859,35.2609 327.18,34.8339 330.501,34.4449 333.822,34.091 337.143,33.769 340.464,33.4762 343.785,33.2101 \n",
       "  347.106,32.9684 350.427,32.7489 353.748,32.5496 357.068,32.3688 360.389,32.2047 363.71,32.0559 367.031,31.9209 370.352,31.7986 373.673,31.6877 376.994,31.5872 \n",
       "  380.315,31.4961 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic function\n",
    "sigmoid(z) = 1 ./ (1 + exp.(-z))\n",
    "plot(-5:0.1:5, sigmoid(-5:0.1:5), xlabel=:z, ylabel=\"sigmoid(z)\", title=\"Logistic Function\", legend=false, size=(400,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting the model\n",
    "\n",
    "Maximum likelihood estimator\n",
    "$$\\max_{\\theta} \\mathbb{P}_{\\theta}\\big( y_1,\\dots,y_n \\big|\\,\\boldsymbol{x}_1,\\dots\\boldsymbol{x}_n \\big)=\\max_\\theta \\prod_i^n\\mathbb{P}_\\theta(y_i| \\boldsymbol{x}_i)$$\n",
    "\n",
    "Because each example is independent of the others.\n",
    "\n",
    "\n",
    "$$\\max_\\theta \\log\\big(\\prod_i^n\\mathbb{P}(y_i|\\boldsymbol{x}_i)\\big)= \\sum_i^m\\log\\big(\\mathbb{P}(y_i|\\boldsymbol{x}_i)\\big)=\\log\\big(\\mathbb{P}(y_1|\\boldsymbol{x}_1)\\big)+\\cdots+\\log\\big(\\mathbb{P}(y_n|\\boldsymbol{x}_n)\\big)$$\n",
    "\n",
    "Because we typically express our objective as a *loss* we can just flip the sign, giving us the *negative log probability:*\n",
    "\n",
    "$$  \\min_\\theta \\Big(- \\sum_i^m\\log\\big(\\mathbb{P}(y_i|\\boldsymbol{x}_i)\\big)\\Big)$$\n",
    "\n",
    "We can write $\\mathbb{P}_\\theta(y_1|z_i)$ compactly as\n",
    "\n",
    "$$\\mathbb{P}_\\theta(y_i|z_i) =\\sigma(z_i)^{y_i}(1-\\sigma(z_i))^{1-y_i},$$\n",
    "\n",
    "$$\n",
    "\\log\\big(\\mathbb{P}_\\theta(y|z)\\big)=yz + \\log\\sigma(-z)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Note that this loss function is commonly called *log loss* and also commonly referred to as *binary cross entropy*. It is a special case of negative log [likelihood](https://en.wikipedia.org/wiki/Likelihood_function). And it is a special case of [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy), which can apply to the multi-class ($>2$) setting. \n",
    "\n",
    "**If instead we were to use the labels $y_i=\\pm1$, the loss function has to modified to $\\log(1+e^{-z})$. This usually leads to a lot of confussion as to why there exists two versions of logistic regression. See [here](https://stats.stackexchange.com/questions/250937/which-loss-function-is-correct-for-logistic-regression/279698#279698) for more information on the topic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Adult Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the Adult dataset taken from the [UCI repository](http://archive.ics.uci.edu/ml/datasets.html). \n",
    "\n",
    " * the dataset contained $14$ features, including age, education, occupation, sex, native-country, among others. In this version, hosted by [National Taiwan University](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html),\n",
    " * The label is a binary indicator indicating whether the person corresponding to each row made more ($y_i = 1$) or less ($y_i = 0$) than $50,000 of income in 1994. \n",
    " * The dataset we're working with contains 30,956 training examples and 1,605 examples set aside for testing. We can download and read the datasets into main memory like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training size = 30296    Testing size = 1605\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_train = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a2a.t\"\n",
    "url_test  = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a\"\n",
    "\n",
    "if !isfile(\"adult.train\")\n",
    "    rawdata_train = readtable(download(url_train, \"adult.train\"), header=false);\n",
    "else\n",
    "    rawdata_train = readtable(\"adult.train\", header=false);\n",
    "end\n",
    "\n",
    "if !isfile(\"adult.test\")\n",
    "    rawdata_test  = readtable(download(url_test, \"adult.test\"), header=false);\n",
    "else\n",
    "    rawdata_test  = readtable(\"adult.test\", header=false);    \n",
    "end\n",
    "\n",
    "@sprintf \"Training size = %d    Testing size = %d\" size(rawdata_train, 1) size(rawdata_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The data consists of lines like the following:\n",
    "\n",
    "-1 4:1 6:1 15:1 21:1 35:1 40:1 57:1 63:1 67:1 73:1 74:1 77:1 80:1 83:1\n",
    "\n",
    "The first entry in each row is the value of the label. The following tokens are the indices of the non-zero features. The number $1$ here is redundant. But we don't always have control over where our data comes from, so we might as well get used to mucking around with weird file formats. Let's write a simple script to process our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processdata (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nonzeroindex(sample)\n",
    "\n",
    "    s      = split(sample, \":1 \") \n",
    "    val    = parse(Int64, split(sample)[1])\n",
    "    s[1]   = split(s[1])[2]\n",
    "    s[end] = split(s[end], \":\")[1]\n",
    "    \n",
    "    output = zeros(Float32, 1, 124)\n",
    "    output[parse.(Int64, s)] = 1\n",
    "    output[end] = val\n",
    "    return output\n",
    "end\n",
    "\n",
    "function processdata(rawdata; atype=Array{Float32})\n",
    "    data = map(atype, [vcat(nonzeroindex.(rawdata[1])...)'])[1];\n",
    "    # change label from {-1,1} to {0,1}\n",
    "    x, y = map(atype, [data[1:end-1, :], (data[end:end, :] + 1) / 2])\n",
    "    return x, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "atype=Array{Float32}; \n",
    "xtrn, ytrn  = processdata(rawdata_train, atype=atype);\n",
    "xtst, ytst  = processdata(rawdata_test, atype=atype);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the fraction of positive examples in our training and test sets. This will give us one nice (necessay but insufficient) sanity check that our training and test data really are drawn from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23993267f0, 0.24610592f0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytrn) / length(ytrn), sum(ytst) / length(ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Knet's mini batch function sets up the stochastic gradient \n",
    "$$\\nabla \\sum_i^m\\log\\big(\\mathbb{P}(y_i|\\boldsymbol{x}_i)\\big) \\approx \\frac{m}{s} \\sum_i^s \\nabla \\log\\big(\\mathbb{P}(y_{\\tau_s}|\\boldsymbol{x}_{\\tau_s})\\big)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here $\\{\\tau_1,\\dots,\\tau_s\\}$ is a random subset of  $\\{1,\\dots,m\\}$. $s$ is called the batch sizes and stochastic gradients are implemented through Knets *minibatch* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = Knet.minibatch(xtrn, ytrn, 64, shuffle=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing the loss\n",
    "*w* here are the weights which are choosen to minimise the cross entropy loss. This achieved by writing the loss and taking the gradient with respect the first variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::gradfun) (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(w, x) = w[1] * x .+ w[2];\n",
    "\n",
    "function loss(w, x, y)\n",
    "    yhat = sigm.(pred(w, x))\n",
    "    return -sum(y .* log.(yhat) + (1-y) .* log.(1-yhat))\n",
    "end\n",
    "lossgradient  = grad(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The training loop consists of an \n",
    "  * outerloop counting the epochs (effective iterations through the data set).\n",
    "  * an inner loop that das gradient descent based on the stochastic gradient of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(w, dtrn; lr=1e-6, epochs=5)\n",
    "    tloss = []\n",
    "    for epoch = 1:epochs\n",
    "        eloss = 0\n",
    "        for (x,y) in dtrn\n",
    "            eloss += loss(w, x, y)\n",
    "            g = lossgradient(w, x, y)\n",
    "            for i = 1:length(w)\n",
    "                w[i] -= lr * g[i]\n",
    "            end\n",
    "        end\n",
    "        push!(tloss, eloss/length(dtrn))\n",
    "    end\n",
    "    \n",
    "    return w, tloss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training output\n",
    "Before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = map(atype, [randn(1, size(xtrn, 1)), zeros(Float32,1,1) ]);\n",
    "#accuracy(w, xtst, ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w, Loss = train(w, dtrn; epochs=30, lr=1e-2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@show accuracy(w, xtrn, ytrn)\n",
    "#@show accuracy(w, xtst, ytst)@show "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpretation of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " * A naive classifier would predict that nobody had an income greater than $50k (the majority class). achieve an accuracy of roughly 75\\%. \n",
    " * By contrast, our classifier gets an accuracy of .84 (results may vary a small amount on each run owing to random initializations and random sampling of the batches).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiclass Logistic Regression \n",
    "\n",
    "\n",
    "* Binary classification is quite useful. (spam vs. not spam or cancer vs not cancer)\n",
    "* $k$ classes  (different handwritten digits).  What can we do?\n",
    " 1. use binary classifier in clever way \n",
    "   * train $K$ different binary classifiers $f_k(\\boldsymbol{x})$ use the one with highest probability\n",
    "   * repeated one vs the rest \n",
    " 2. generate an output that is  a discrete probability distribution over the $K$ classes. \n",
    " \n",
    "This *softmax* function achieves this by \n",
    "\n",
    "$$\\mbox{softmax}(\\boldsymbol{z}) = \\frac{e^{\\boldsymbol{z}} }{\\sum_{k=1}^K e^{z_i}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Because now we have $K$ outputs - we can represent this graphically.\n",
    "![](../img/simple-softmax-net.png)\n",
    "\n",
    " mapping from inputs to outputs via a matrix-vector product $W \\boldsymbol{x} + \\boldsymbol{b}$:\n",
    "\n",
    "$$\\hat{y} = \\mbox{softmax}(W\\boldsymbol{x} + \\boldsymbol{b})$$\n",
    "\n",
    "This model is sometimes called *multiclass logistic regression*, *softmax regression* and *multinomial regression*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "In this example we build a simple classification model for the [MNIST](http://yann.lecun.com/exdb/mnist/) handwritten digit recognition dataset. MNIST has 60000 training and 10000 test examples. Each input x consists of 784 pixels representing a 28x28 image. The corresponding output indicates the identity of the digit 0..9.\n",
    "\n",
    "![png](https://jamesmccaffrey.files.wordpress.com/2014/06/firsteightimages.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To start, we'll use Knet's utilities for grabbing a copy of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoading MNIST...\n",
      "\u001b[39m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k  100 9680k    0     0  2638k      0  0:00:03  0:00:03 --:--:-- 2638k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k  100 1610k    0     0  4609k      0 --:--:-- --:--:-- --:--:-- 4613k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881  100 28881    0     0   332k      0 --:--:-- --:--:-- --:--:--  335k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542  100  4542    0     0  68324      0 --:--:-- --:--:-- --:--:-- 68818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], UInt8[0x05, 0x0a, 0x04, 0x01, 0x09, 0x02, 0x01, 0x03, 0x01, 0x04  …  0x09, 0x02, 0x09, 0x05, 0x01, 0x08, 0x03, 0x05, 0x06, 0x08], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], UInt8[0x07, 0x02, 0x01, 0x0a, 0x04, 0x01, 0x04, 0x09, 0x05, 0x09  …  0x07, 0x08, 0x09, 0x0a, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for p in (\"GZip\",)\n",
    "    Pkg.installed(p) == nothing && Pkg.add(p)\n",
    "end\n",
    "\n",
    "using GZip\n",
    "\n",
    "\"Where to download mnist from\"\n",
    "mnisturl = \"http://yann.lecun.com/exdb/mnist\"\n",
    "\n",
    "\"Where to download mnist to\"\n",
    "mnistdir = \"./\"\n",
    "\n",
    "\"\"\"\n",
    "This utility loads the [MNIST](http://yann.lecun.com/exdb/mnist)\n",
    "hand-written digits dataset.  There are 60000 training and 10000 test\n",
    "examples. Each input x consists of 784 pixels representing a 28x28\n",
    "grayscale image.  The pixel values are converted to Float32 and\n",
    "normalized to [0,1].  Each output y is a UInt8 indicating the correct\n",
    "class.  10 is used to represent the digit 0.\n",
    "```\n",
    "# Usage:\n",
    "include(Pkg.dir(\"Knet/data/mnist.jl\"))\n",
    "xtrn, ytrn, xtst, ytst = mnist()\n",
    "# xtrn: 28×28×1×60000 Array{Float32,4}\n",
    "# ytrn: 60000-element Array{UInt8,1}\n",
    "# xtst: 28×28×1×10000 Array{Float32,4}\n",
    "# ytst: 10000-element Array{UInt8,1}\n",
    "```\n",
    "\"\"\"\n",
    "function mnist()\n",
    "    global _mnist_xtrn,_mnist_ytrn,_mnist_xtst,_mnist_ytst\n",
    "    if !isdefined(:_mnist_xtrn)\n",
    "        info(\"Loading MNIST...\")\n",
    "        _mnist_xtrn = _mnist_xdata(\"train-images-idx3-ubyte.gz\")\n",
    "        _mnist_xtst = _mnist_xdata(\"t10k-images-idx3-ubyte.gz\")\n",
    "        _mnist_ytrn = _mnist_ydata(\"train-labels-idx1-ubyte.gz\")\n",
    "        _mnist_ytst = _mnist_ydata(\"t10k-labels-idx1-ubyte.gz\")\n",
    "    end\n",
    "    return _mnist_xtrn,_mnist_ytrn,_mnist_xtst,_mnist_ytst\n",
    "end\n",
    "\n",
    "\"Utility to view a MNIST image, requires the Images package\"\n",
    "mnistview(x,i)=colorview(Gray,permutedims(x[:,:,1,i],(2,1)))\n",
    "\n",
    "function _mnist_xdata(file)\n",
    "    a = _mnist_gzload(file)[17:end]\n",
    "    reshape(a ./ 255f0, (28,28,1,div(length(a),784)))\n",
    "end\n",
    "\n",
    "function _mnist_ydata(file)\n",
    "    a = _mnist_gzload(file)[9:end]\n",
    "    a[a.==0] = 10\n",
    "    # full(sparse(a,1:length(a),1f0,10,length(a)))\n",
    "    return a\n",
    "end\n",
    "\n",
    "function _mnist_gzload(file)\n",
    "    if !isdir(mnistdir)\n",
    "        mkpath(mnistdir)\n",
    "    end\n",
    "    path = joinpath(mnistdir,file)\n",
    "    if !isfile(path)\n",
    "        url = \"$mnisturl/$file\"\n",
    "        download(url, path)\n",
    "    end\n",
    "    f = gzopen(path)\n",
    "    a = read(f)\n",
    "    close(f)\n",
    "    return(a)\n",
    "end\n",
    "xtrn, ytrn, xtst, ytst = mnist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are two parts of the dataset for training and testing. Each part has N items and each item is a tuple of an image and a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1, 60000), (60000,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrn, ytrn, xtst, ytst = mnist()\n",
    "\n",
    "size(xtrn), size(ytrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each image has been formatted as a 3-tuple (height, width, channel). For color images, the channel would have 3 dimensions (red, green and blue). In this case we have a gray scale image with a single channel. Note that `ytrn` is a `Array{UInt8,1}` data type. Let us take a look at these labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(UInt8[0x05, 0x0a, 0x04, 0x01, 0x09, 0x02, 0x01, 0x03, 0x01, 0x04], [5, 10, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrn[1:10], 1ytrn[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ok, let us now use Knet's minibatch function to prepare the date for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = minibatch(xtrn, ytrn, 100; xtype=atype);\n",
    "dtst = minibatch(xtst, ytst, 100; xtype=atype);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input images have been reshaped to 784x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{Float32,N} where N, Array{UInt8,1})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrn.xtype, dtrn.ytype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Multiclass logistic regression\n",
    "\n",
    "### Multiclass logistic regression\n",
    "\n",
    "Given $W$ and $b$ what is the loss?\n",
    "\n",
    " 1. The misclassification loss function: counts the number of instances inaccurately classified\n",
    " 2. Similar to logistic regression we would like to take gradients to find $W_{opt}$ and $b_{opt}$\n",
    "\n",
    "\n",
    "The relevant loss function here is called [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy). The cross entropy between two probability distributions $p$ and $q$ is defined as\n",
    "\n",
    "$$H(p,q)=\\operatorname {E}_{p}[-\\log q]=H(p)+D_{{{\\mathrm  {KL}}}}(p\\|q)=-\\sum_{i=1}^n p_i \\log q_i$$\n",
    "\n",
    "We typically observe fixed labels corresponding to $p_{i}=\\begin{cases}\n",
    "1 & i=k\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$.\n",
    "\n",
    "Thus the loss corresponds to the log loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "Assument that $y$ is an $K\\times m$ matrix, where $m$ is the number of samples and $K$ is the number of labels. A Naive implementaion of this theory is a follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cross_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z) = exp.(z) ./ sum(exp.(z), 1)\n",
    "cross_entropy(yhat, y) = - sum(y .* log.(yhat), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000;\n",
    "K = 10;\n",
    "z = rand(K, m);\n",
    "yhat = softmax(z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that indeed all of our rows sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1000 Array{Float64,2}:\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapslices(sum, yhat, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We could then implement the loss functions as: (in the code of Knet a more numerically stable version is implemented as nll )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cross_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(yhat, y) = - sum(sum(z .* log.(z), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient descent for multiclass logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::gradfun) (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(w,x) = w[1]*mat(x) .+ w[2] # mat takes 28,28,1,N) x array to a (784,N).\n",
    "loss(w,x,ygold) = nll(predict(w,x), ygold)\n",
    "lossgradient = grad(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model on the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(w, data; lr=.1)\n",
    "    for (x,y) in data\n",
    "        dw = lossgradient(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "        end   \n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: atype not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: atype not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "w = map(atype, Any[ 0.1f0*randn(Float32, 10, 784), zeros(Float32, 10, 1) ])\n",
    "w = Any[ 0.1f0*randn(Float32,10,784), zeros(Float32,10,1) ];\n",
    "println((:epoch, 0, :trn, accuracy(w,dtrn,predict), :tst, accuracy(w,dtst,predict)))\n",
    "for epoch=1:10\n",
    "    train(w, dtrn; lr=0.5)\n",
    "    println((:epoch, epoch, :trn, accuracy(w,dtrn,predict), :tst, accuracy(w,dtst,predict)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ok, let us check the accuracy on the testing and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9193666666666667, 0.9164)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(w, dtrn, predict), accuracy(w, dtst, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might reasonably conclude that this problem is too easy to be taken seriously by experts.\n",
    "But until recently, many papers (Google Scholar says 13,800) were published using results obtained on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multilayer perceptrons from scratch\n",
    "\n",
    "Multiclass logistic regression based on $$\\hat{y} = \\mbox{softmax}(W \\boldsymbol{x} + b)$$to  **deep neural networks** with multiple layers.\n",
    "\n",
    "\n",
    "Graphically, we could depict the model like this:\n",
    "![](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/img/simple-softmax-net.png?raw=true)\n",
    "\n",
    "\n",
    " * *But linearity is a strong assumption*. - each pixel,  increasing its value either increases probability that it depicts a dog or decreases it.\n",
    "\n",
    "We can model a more general class of functions by incorporating one or more *hidden layers*.\n",
    "Each layer feeds in to the layer above it, until we generate an output.\n",
    "This architecture is commonly called a **\"multilayer perceptron\"**.\n",
    "\n",
    "$$ h_1 = \\phi(W_1\\boldsymbol{x} + b_1) $$\n",
    "$$ h_2 = \\phi(W_2\\boldsymbol{h_1} + b_2) $$\n",
    "$$...$$\n",
    "$$ h_n = \\phi(W_n\\boldsymbol{h_{n-1}} + b_n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " * each layer has its own parameters $W_i$ and $b_i$  \n",
    " * its output is feed throughactivation function for the hidden layers as $\\phi$\n",
    " * topmost hidden layer,  for classification, we'll stick with the softmax activation in the output layer.\n",
    "\n",
    "$$ \\hat{y} = \\mbox{softmax}(W_y \\boldsymbol{h}_n + b_y)$$\n",
    "\n",
    "Graphically, a multilayer perceptron could be depicted like this:\n",
    "\n",
    "![](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/img/multilayer-perceptron.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 600 400\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip9700\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"600\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip9700)\" points=\"\n",
       "0,400 600,400 600,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip9701\">\n",
       "    <rect x=\"120\" y=\"0\" width=\"421\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip9700)\" points=\"\n",
       "29.4661,377.965 580.315,377.965 580.315,11.811 29.4661,11.811 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip9702\">\n",
       "    <rect x=\"29\" y=\"11\" width=\"552\" height=\"367\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,377.965 29.4661,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  167.178,377.965 167.178,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  304.891,377.965 304.891,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  442.603,377.965 442.603,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  580.315,377.965 580.315,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,377.965 580.315,377.965 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,316.939 580.315,316.939 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,255.913 580.315,255.913 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,194.888 580.315,194.888 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,133.862 580.315,133.862 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,72.8366 580.315,72.8366 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  29.4661,11.811 580.315,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,377.965 580.315,377.965 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,377.965 29.4661,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,377.965 29.4661,372.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  167.178,377.965 167.178,372.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  304.891,377.965 304.891,372.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  442.603,377.965 442.603,372.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  580.315,377.965 580.315,372.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,377.965 37.7289,377.965 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,316.939 37.7289,316.939 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,255.913 37.7289,255.913 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,194.888 37.7289,194.888 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,133.862 37.7289,133.862 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,72.8366 37.7289,72.8366 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,11.811 37.7289,11.811 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 29.4661, 391.765)\" x=\"29.4661\" y=\"391.765\">-5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 167.178, 391.765)\" x=\"167.178\" y=\"391.765\">-2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 304.891, 391.765)\" x=\"304.891\" y=\"391.765\">0.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 442.603, 391.765)\" x=\"442.603\" y=\"391.765\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 580.315, 391.765)\" x=\"580.315\" y=\"391.765\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 382.465)\" x=\"23.4661\" y=\"382.465\">-1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 321.439)\" x=\"23.4661\" y=\"321.439\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 260.413)\" x=\"23.4661\" y=\"260.413\">1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 199.388)\" x=\"23.4661\" y=\"199.388\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 138.362)\" x=\"23.4661\" y=\"138.362\">3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 77.3366)\" x=\"23.4661\" y=\"77.3366\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 23.4661, 16.311)\" x=\"23.4661\" y=\"16.311\">5</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,316.939 84.551,316.939 139.636,316.939 194.721,316.939 249.806,316.939 304.891,316.939 580.315,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9702)\" style=\"stroke:#e26f46; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  29.4661,377.965 84.551,365.759 139.636,353.554 194.721,341.349 249.806,329.144 304.891,316.939 580.315,11.811 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip9700)\" points=\"\n",
       "489.608,78.051 562.315,78.051 562.315,32.691 489.608,32.691 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  489.608,78.051 562.315,78.051 562.315,32.691 489.608,32.691 489.608,78.051 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  495.608,47.811 531.608,47.811 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:start;\" transform=\"rotate(0, 537.608, 52.311)\" x=\"537.608\" y=\"52.311\">y1</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip9700)\" style=\"stroke:#e26f46; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  495.608,62.931 531.608,62.931 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9700)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:start;\" transform=\"rotate(0, 537.608, 67.431)\" x=\"537.608\" y=\"67.431\">y2</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Activation energy\n",
    "function leaky_relu(x, alpha=0.2)\n",
    "    pos = max(0,x)\n",
    "    neg = min(0,x) * alpha\n",
    "    return pos + neg\n",
    "end\n",
    "xs=[-5.0:0.1,5;]\n",
    "plot(xs,relu.(xs))\n",
    "plot!(xs,leaky_relu.(xs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Remark\n",
    " * It's easy to design a hidden node that that do arbitrary computation,\n",
    "say logical operations.\n",
    " * Any function can be approximated by single-hidden-layer neural network\n",
    " * Actually learning the weights that function is the hard part. (might be easier for deeper networks)\n",
    " * Choice of architecture is tricky and a craft\n",
    "  * Fully connected layer has many parameters - special purpose convolutional layers \n",
    "  * inspired from our brain - e.g. visual cortex\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "xtrn, ytrn, xtst, ytst = mnist()\n",
    "dtrn = minibatch(xtrn, ytrn, 100, xtype=atype);\n",
    "dtst = minibatch(xtst, ytst, 100, xtype=atype);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initweights (generic function with 2 methods)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initweights(d, scale=0.01; hidden=[2], atype=Array{Float32})\n",
    "    model = Vector{Any}(2 * length(hidden))\n",
    "    X = d\n",
    "    for k = 1:length(hidden)\n",
    "        H = hidden[k]\n",
    "        model[2k - 1] = scale * randn(H, X) \n",
    "        model[2k]     = scale * randn(H, 1)\n",
    "        X = H\n",
    "    end\n",
    "    return map(atype, model)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can define the function `initmodel` with the desired parameters. The variable `hidden` contains the output sizes for each of the layers, and `num_inputs` is the size of the input variable `x` (in this case $x\\in\\mathbb{R}^{784}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initmodel (generic function with 1 method)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initmodel(atype;num_inputs=784,num_hidden=256,num_outputs=10)\n",
    "    return initweights(num_inputs,hidden=[num_hidden,num_hidden,num_outputs]; atype=atype);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(w, x)\n",
    "    x = mat(x)\n",
    "    for i=1:2:length(w) - 2\n",
    "        x = relu.(w[i] * x .+ w[i+1]) # bias an weights are concatendated \n",
    "    end\n",
    "    return w[end - 1]*x .+ w[end]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's test the predict function to make sure everything works fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×100 Array{Float32,2}:\n",
       "  0.00317245    0.00296181   0.00431252  …   0.00420051    0.00406494\n",
       " -0.000207197   0.00048806   0.00188734      0.000203192   0.00054854\n",
       " -0.00655995   -0.00656218  -0.00695875     -0.00755201   -0.00675453\n",
       " -0.00516264   -0.0047246   -0.00538845     -0.00460281   -0.005425  \n",
       "  0.0079966     0.00766712   0.00719482      0.00668695    0.00700066\n",
       " -0.0102388    -0.0106978   -0.00952904  …  -0.0110641    -0.0117366 \n",
       "  0.0072579     0.00667939   0.00485501      0.00494138    0.00350948\n",
       " -0.00485248   -0.0036854   -0.00550467     -0.00434778   -0.00465735\n",
       " -0.00829852   -0.00845978  -0.00789331     -0.00837211   -0.00853347\n",
       " -0.0129301    -0.0124188   -0.0118805      -0.012602     -0.0109624 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (x, y) in dtrn\n",
    "    display(predict(initmodel(atype), x))\n",
    "    break \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 2 methods)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(w, x, ygold, predict) = nll(predict(w, x), ygold);\n",
    "lossgradient = grad(loss); # AutoGrad means we don't need backpropagation\n",
    "\n",
    "function train(w, dtrn, optim, predict; epochs=10)\n",
    "    for epoch = 1:epochs\n",
    "        for (x, y) in dtrn\n",
    "            g = lossgradient(w, x, y, predict)\n",
    "            update!(w, g, optim) ## this a generic train loop the gradient update can be replaced as appropriate\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimizer (SGD) and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim(w; lr=0.01) = optimizers(w, Sgd;  lr=lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report (generic function with 1 method)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function report(epoch, w, dtrn, dtst, predict)\n",
    "    println((:epoch, epoch, :trn, accuracy(w, dtrn, predict), :tst, accuracy(w, dtst, predict)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "w   = initmodel(atype);\n",
    "opt = optim(w, lr=1e-1);\n",
    "fast=true\n",
    "nepochs=2\n",
    "if fast\n",
    "    train(w, dtrn, opt, predict; epochs=nepochs)\n",
    "else\n",
    "    for epoch = 1:nepochs\n",
    "        train(w, dtrn, opt, predict, epochs=1)\n",
    "        report(epoch, w, dtrn, dtst, predict)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A complete MNIST training code from the collections of cells above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mInitialze Model ...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mStart Training Model ...\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "using AutoGrad\n",
    "using Knet, Plots, DataFrames\n",
    "gr()\n",
    "\n",
    "for p in (\"GZip\",)\n",
    "    Pkg.installed(p) == nothing && Pkg.add(p)\n",
    "end\n",
    "\n",
    "using GZip\n",
    "\n",
    "# atype definition:\n",
    "atype=Array{Float32};\n",
    "\n",
    "# Functions for MNIST data download next:\n",
    "\"Where to download mnist from\"\n",
    "mnisturl = \"http://yann.lecun.com/exdb/mnist\"\n",
    "\n",
    "\"Where to download mnist to\"\n",
    "mnistdir = \"./\"\n",
    "\n",
    "\"\"\"\n",
    "This utility loads the [MNIST](http://yann.lecun.com/exdb/mnist)\n",
    "hand-written digits dataset.  There are 60000 training and 10000 test\n",
    "examples. Each input x consists of 784 pixels representing a 28x28\n",
    "grayscale image.  The pixel values are converted to Float32 and\n",
    "normalized to [0,1].  Each output y is a UInt8 indicating the correct\n",
    "class.  10 is used to represent the digit 0.\n",
    "```\n",
    "# Usage:\n",
    "include(Pkg.dir(\"Knet/data/mnist.jl\"))\n",
    "xtrn, ytrn, xtst, ytst = mnist()\n",
    "# xtrn: 28×28×1×60000 Array{Float32,4}\n",
    "# ytrn: 60000-element Array{UInt8,1}\n",
    "# xtst: 28×28×1×10000 Array{Float32,4}\n",
    "# ytst: 10000-element Array{UInt8,1}\n",
    "```\n",
    "\"\"\"\n",
    "function mnist()\n",
    "    global _mnist_xtrn,_mnist_ytrn,_mnist_xtst,_mnist_ytst\n",
    "    if !isdefined(:_mnist_xtrn)\n",
    "        info(\"Loading MNIST...\")\n",
    "        _mnist_xtrn = _mnist_xdata(\"train-images-idx3-ubyte.gz\")\n",
    "        _mnist_xtst = _mnist_xdata(\"t10k-images-idx3-ubyte.gz\")\n",
    "        _mnist_ytrn = _mnist_ydata(\"train-labels-idx1-ubyte.gz\")\n",
    "        _mnist_ytst = _mnist_ydata(\"t10k-labels-idx1-ubyte.gz\")\n",
    "    end\n",
    "    return _mnist_xtrn,_mnist_ytrn,_mnist_xtst,_mnist_ytst\n",
    "end\n",
    "\n",
    "\"Utility to view a MNIST image, requires the Images package\"\n",
    "mnistview(x,i)=colorview(Gray,permutedims(x[:,:,1,i],(2,1)))\n",
    "\n",
    "function _mnist_xdata(file)\n",
    "    a = _mnist_gzload(file)[17:end]\n",
    "    reshape(a ./ 255f0, (28,28,1,div(length(a),784)))\n",
    "end\n",
    "\n",
    "function _mnist_ydata(file)\n",
    "    a = _mnist_gzload(file)[9:end]\n",
    "    a[a.==0] = 10\n",
    "    # full(sparse(a,1:length(a),1f0,10,length(a)))\n",
    "    return a\n",
    "end\n",
    "\n",
    "function _mnist_gzload(file)\n",
    "    if !isdir(mnistdir)\n",
    "        mkpath(mnistdir)\n",
    "    end\n",
    "    path = joinpath(mnistdir,file)\n",
    "    if !isfile(path)\n",
    "        url = \"$mnisturl/$file\"\n",
    "        download(url, path)\n",
    "    end\n",
    "    f = gzopen(path)\n",
    "    a = read(f)\n",
    "    close(f)\n",
    "    return(a)\n",
    "end\n",
    "\n",
    "# The function to set the initial weights of Network:\n",
    "function initweights(d, scale=0.01; hidden=[2], atype=Array{Float32})\n",
    "    model = Vector{Any}(2 * length(hidden))\n",
    "    X = d\n",
    "    for k = 1:length(hidden)\n",
    "        H = hidden[k]\n",
    "        model[2k - 1] = scale * randn(H, X) \n",
    "        model[2k]     = scale * randn(H, 1)\n",
    "        X = H\n",
    "    end\n",
    "    return map(atype, model)\n",
    "end\n",
    "\n",
    "# Function to initialize the model Neural Network:\n",
    "#    num_inputs: Number of input values in input layer\n",
    "#    num_hidden: Number of nodes at each hidden layers\n",
    "#    num_outputs: Number of values at output layer\n",
    "#    hidden: the list of layers that does not include input layer\n",
    "function initmodel(atype;num_inputs=784,num_hidden=256,num_outputs=10)\n",
    "    return initweights(num_inputs,hidden=[num_hidden,num_hidden,num_outputs]; atype=atype);\n",
    "end\n",
    "\n",
    "# The next function defines how we determine the prediction:\n",
    "#  w: tensor of weights (See length(w) for first dimension, which is the number of layers in NN!)\n",
    "#     But wait, the number of layers are doubled since there are also bias values. \n",
    "#     Check the initweights function!\n",
    "#  x: input values\n",
    "function predict(w, x)\n",
    "    x = mat(x)\n",
    "    for i=1:2:length(w) - 2\n",
    "        x = relu.(w[i] * x .+ w[i+1]) # bias an weights are concatendated \n",
    "    end\n",
    "    return w[end - 1]*x .+ w[end]\n",
    "end\n",
    "\n",
    "# Definition of optimizer (Here it is SGD, Stochastic Gradient Descent)\n",
    "optim(w; lr=0.01) = optimizers(w, Sgd;  lr=lr);\n",
    "\n",
    "# Definition of loss function and its gradient:\n",
    "loss(w, x, ygold, predict) = nll(predict(w, x), ygold);\n",
    "lossgradient = grad(loss); # AutoGrad means we don't need backpropagation\n",
    "\n",
    "# Definition of training function:\n",
    "function train(w, dtrn, optim, predict; epochs=10)\n",
    "    for epoch = 1:epochs\n",
    "        for (x, y) in dtrn\n",
    "            g = lossgradient(w, x, y, predict)\n",
    "            update!(w, g, optim) ## this a generic train loop the gradient update can be replaced as appropriate\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Fancy printing of how successful is the network predictions: accuracy of training (trn) and test (tst) datasets\n",
    "function report(epoch, w, dtrn, dtst, predict)\n",
    "    println((:epoch, epoch, :trn, accuracy(w, dtrn, predict), :tst, accuracy(w, dtst, predict)))\n",
    "end\n",
    "\n",
    "# MNIST download:\n",
    "xtrn, ytrn, xtst, ytst = mnist()\n",
    " \n",
    "# Minibatch definitions:\n",
    "size_of_batch = 100\n",
    "dtrn = minibatch(xtrn, ytrn, size_of_batch; xtype=atype);\n",
    "dtst = minibatch(xtst, ytst, size_of_batch; xtype=atype);\n",
    "\n",
    "# Activation function definitions:\n",
    "#softmax(z) = exp.(z) ./ sum(exp.(z), 1)\n",
    "#cross_entropy(yhat, y) = - sum(y .* log.(yhat), 1)\n",
    "\n",
    "# And finally training the network!\n",
    "w   = initmodel(atype);\n",
    "opt = optim(w, lr=1e-1);\n",
    "fast=true\n",
    "nepochs=2\n",
    "if fast\n",
    "    train(w, dtrn, opt, predict; epochs=nepochs)\n",
    "else\n",
    "    for epoch = 1:nepochs\n",
    "        train(w, dtrn, opt, predict, epochs=1)\n",
    "        report(epoch, w, dtrn, dtst, predict)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:trn, 0.9143333333333333, :tst, 0.9125)\n"
     ]
    }
   ],
   "source": [
    "println((:trn, accuracy(w, dtrn, predict), :tst, accuracy(w, dtst, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond basic Neural Nets and tricks of the trade\n",
    "\n",
    " * \"better\" optimisers, see a nice [blog post](http://sebastianruder.com/optimizing-gradient-descent/)\n",
    "  * Adam reduce noise by taking geometric average of gradients, and scale by componentwise standarddeviation estimate\n",
    "  * \"train in parallel\" - elastic averaged stochastic gradient\n",
    " * initialisation of neural nets Xavier (variance inverse proportional to number of connections of neurons)\n",
    " * regularisation overfitting - perturbing with noise the input (slight change to image should not change label), randomly disable neurons (dropout)\n",
    " * Transfer learning incorporate neural network trained on one data set for another task\n",
    "  * use as part of architecture and online retrain new components\n",
    "  * the neural network based classifing cats and dogs can help to detect skin cancer in this [Nature publication ](https://www.nature.com/articles/nature21056?error=cookies_not_supported&code=fab53529-b08e-48c2-a26a-72c23e3d69e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
