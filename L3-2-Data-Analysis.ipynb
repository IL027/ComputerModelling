{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using FreqTables\n",
    "using Plots\n",
    "using StatPlots\n",
    "using RDatasets\n",
    "using Distributions\n",
    "using DecisionTree\n",
    "\n",
    "plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# IL027 Core Lecture 3 part 2 - Data Analysis\n",
    "\n",
    "### James Kermode\n",
    "\n",
    "### School of Engineering\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Reading datasets\n",
    "- Visualisation\n",
    "- Clustering and classification\n",
    "- Missing data\n",
    "- Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Iris Dataset\n",
    "\n",
    "## Loading Data and Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the classic [Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), from a 1936 paper by Ronald Fisher. We can load this from the `RDatasets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = dataset(\"datasets\", \"iris\")\n",
    "head(iris) # print the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Size and Shape of Data\n",
    "\n",
    "The `DataFrames` packages provides a number of functions to describe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show size(iris)\n",
    "@show nrow(iris)\n",
    "@show ncol(iris)\n",
    "@show names(iris)\n",
    "@show eltypes(iris);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "describe(iris[:Species])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are three possible values for the species in this dataset. The `levels()` function identifies what these are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = levels(iris[:Species])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualisation\n",
    "\n",
    "### Scatter Plots\n",
    "\n",
    "We start with a 2D scatter plot, to show the relationship between two variables, e.g. sepal width and sepal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(iris[:SepalWidth], iris[:SepalLength], group=iris[:Species], \n",
    "        markershape=:xcross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is a special syntax for plotting dataframes which saves a bit of typing, e.g. to look now at petal width vs. petal length. This uses the `@df` macro (similar to `@show` that we saw earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df iris scatter(:PetalWidth, :PetalLength, group=:Species,\n",
    "                 markershape=:xcross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Histogram\n",
    "\n",
    "Histograms are useful to visualise the distribution of individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = @df iris histogram(:PetalLength, bins=30, label=\"PetalLength\", c=1)\n",
    "p2 = @df iris histogram(:PetalWidth, bins=30, label=\"PetalWidth\", c=2)\n",
    "\n",
    "plot(p1, p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Marginal histograms\n",
    "\n",
    "Marginal histograms allow the correlation between two variables to be assessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df iris marginalhist(:PetalLength, :PetalWidth, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation plot\n",
    "\n",
    "A correlation plot combines histograms for each variable (diagonal) with marginal histograms (above diagonal) and scatter plots for each pair (below diagonal)\n",
    "\n",
    "**Lecture Question** Which variables would you expect to be correlated with one another? Does this match what you see here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df iris corrplot([:SepalLength :SepalWidth :PetalLength :PetalWidth], bins=20, grid=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've played around with our data a little, let's try to do some more detailed analysis. We would like to learn the relationship between the four variables and the species of iris. \n",
    "\n",
    "We can do this using clustering (*unsupervised learning*, i.e. only the features without labels are used) or classification (*supervised learing*, i.e. we provide the labels for a training set).\n",
    "\n",
    "**K-means clustering** is a classic method for clustering that produces a fixed number $K$ of clusters, based on solving the optimisation problem\n",
    "\n",
    "$$\n",
    "\\mathrm{minimize} \\ \\| \\mathbf{x}_i - \\boldsymbol{\\mu}_{z_i} \\|^2\n",
    "\\mathrm{with\\ respect\\ to} \\ (\\boldsymbol{\\mu}, z)\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\mu}_k$ is the center of the $k$-th cluster, and $z_i$ indicates the cluster for $\\mathbf{x}_i$. The implementation is fairly straighforward; here is an unoptimised version, see also `Clustering` package for faster code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function kmeans(data, K; means=nothing, update_means=true)\n",
    "    N, M = size(data)\n",
    "    if means == nothing\n",
    "        # Initialise centers randomly within range of data        \n",
    "        means = hcat([rand(Uniform(dmin, dmax), K) for (dmin, dmax) \n",
    "                        in zip(minimum(data,1), maximum(data,1)) ]...)\n",
    "    end\n",
    "    assign, oldassign = zeros(Int, N), zeros(Int, N)\n",
    "    while true\n",
    "       for n in 1:N  # E-step - update the assignment\n",
    "           d = data[n, :] .- means' # distance from all the means\n",
    "           dmin, kmin = findmin([norm(d[:, i]) for i=1:K])\n",
    "           assign[n] = kmin # assign point to closest centre\n",
    "       end\n",
    "       all(oldassign == assign) && break # if nothing changed, we're done\n",
    "       oldassign = copy(assign)\n",
    "        \n",
    "       if update_means\n",
    "           means[:] = 0.0 # M-step - update the centers\n",
    "           for k in 1:K\n",
    "               any(assign .== k) && (means[k,:] = mean(data[assign .== k, :], 1))\n",
    "           end\n",
    "       end\n",
    "   end\n",
    "   return (assign, means)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying K-means to the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = convert(Array, iris[:, 1:4])\n",
    "labels = convert(Array, iris[:, :Species])\n",
    "\n",
    "assign, means = kmeans(features, 3); # K=3 clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the true assignment with the one we get from K-means using scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cols = [1, 2]\n",
    "p1 = scatter(iris[:,cols[1]], iris[:,cols[2]], \n",
    "             group=labels, marker=:xcross, ms=3, title=\"True Assignment\",\n",
    "             xlabel=names(iris)[cols[1]], ylabel=names(iris)[cols[2]])\n",
    "p2 = scatter(iris[:,cols[1]], iris[:,cols[2]], group=assign, \n",
    "             marker=:xcross, ms=3, title=\"K-means\",\n",
    "             xlabel=names(iris)[cols[1]], ylabel=names(iris)[cols[2]])\n",
    "scatter!(means[:,cols[1]], means[:,cols[2]], ms=5, \n",
    "         label=\"Centers\", color=[:blue, :red, :green])\n",
    "plot(p1, p2, layout=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "The confusion matrix gives the number of results in each class, with predictions on rows and true labels as columns. This means we can see at a glance how many assignments are correct (diagonal entries) and how many are wrong (off-diagonal). Because the assignments are based on distance, $K$-means only works well for roughly spherical clusters.\n",
    "\n",
    "We're using the `confusion_matrix` function from `DataFrames`, but it would be easy to code up by hand. Since the clustering was unsupervised, we first have to match up the labels and assignments by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function assign2predict(g)\n",
    "    if g == 3\n",
    "        return \"setosa\"\n",
    "    elseif g == 2\n",
    "        return \"versicolor\"\n",
    "    elseif g == 1\n",
    "        return \"virginica\"\n",
    "    end\n",
    "end\n",
    "predictions = assign2predict.(assign)\n",
    "cm = confusion_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Lecture Question** Write an expression to compute the accuracy, which is given by the ratio of the number of correct predictions to the total number of predictions. Compare it to the answer given by the `confusion_matrix()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Manual_decision_tree.jpg/220px-Manual_decision_tree.jpg\" align=\"right\" width=\"25%\">\n",
    "\n",
    "This is based on the idea of a tree of decisions, which you may be familiar with from conditional probability.\n",
    "\n",
    "Here, the target value can take a discrete set of values, so this is called a *classification tree*. Leaves represent labels and branches represent combinations of features that lead to those class labels. Decision trees can also be used for *regression*, that is where the target variable is continouous.\n",
    "\n",
    "This is an example of a *supervised learning* appraoach. We will use the implementation in the `DecisionTree` package.\n",
    "First we need to split our dataset into ~2/3 training and ~1/3 test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train = rand(nrow(iris)) .< 2/3\n",
    "test = .!train \n",
    "sum(train), sum(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_tree(labels[train], features[train,:])\n",
    "print_tree(model, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We first check for consistency on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = apply_tree(model, features[train,:])\n",
    "cm = confusion_matrix(labels[train], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we apply to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = apply_tree(model, features[test, :])\n",
    "cm = confusion_matrix(labels[test], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remark: supervised learning with K-means\n",
    "\n",
    "We could adapt the K-means algorithm to do supervised learning by initially allowing the means to move when clustering from the training data, and then fixing the means before predicting on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_train, means = kmeans(features[train,:], 3, means=means, update_means=true) \n",
    "assign_test, means = kmeans(features[test,:], 3, means=means, update_means=false)\n",
    "\n",
    "predict_test = assign2predict.(assign_test)\n",
    "cm = confusion_matrix(labels[test], predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is suprisingly good on this dataset for such a simple algorithm. However, note we had to choose the number of clusters and map the clusters to labels by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Titanic Dataset\n",
    "\n",
    "We now move onto a more challenging dataset, taken from the passenger records for the *RMS Titanic*, which sank on the 14th April 1912 with the loss of more than 1500 lives. The task is to use data such as the age, sex and fare paid by a passenger to predict whether they survived or not. As before, we will use a portion of the dataset to train a predictive model, and then assess it using the remaining test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = readtable(\"titanic.csv\")\n",
    "head(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "describe(titanic[:Survived])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Counting values is such a common operation that there's a special function for it, `countmap`. \n",
    "\n",
    "`freqtable` from the `FreqTables` package does the same thing, but produces easier to read output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countmap(titanic[:Survived])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(titanic, :Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also group by multiple values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(titanic, :Survived, :Sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To make things a bit more readable, let's replace 0 and 1 with labels `Dead` and `Survived`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum SurvivedType Dead=0 Survived=1\n",
    "titanic[:Survived] = SurvivedType.(titanic[:Survived]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(titanic, :Survived, :Sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with missing data\n",
    "\n",
    "If we try to make a table of the `Embarked` column we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(titanic, :Embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see why by describing this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(titanic[:Embarked])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two missing values, denoted `NA` for \"not applicable\". We can neglect these with the `dropna()` function, which returns a copy of the  data with missing values removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "freqtable(dropna(titanic[:Embarked]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've dropped the missing data, we see there are three different embarkation points: Cherbourg (C), Queenstown (Q), or Southampton (S). Southampton is the most popular (modal value), so let's fill in the missing values with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mode = mode(dropna(titanic[:Embarked]))\n",
    "titanic[isna.(titanic[:Embarked]), :Embarked] = embarked_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have a similar problem with `Age`, where 20% of the data are missing. \n",
    "\n",
    "**Lecture Question** We will simply delete those rows for now, but can you think of a better solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(titanic[:Age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "titanic = titanic[.!isna.(titanic[:Age]), :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(titanic[:Age])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualisation\n",
    "\n",
    "Let's start digging into the data with some pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "male = titanic[titanic[:Sex] .== \"male\", :]\n",
    "female = titanic[titanic[:Sex] .== \"female\", :]\n",
    "pie([\"Dead\", \"Survived\"], freqtable(male, :Survived), title=\"Male\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Histogram\n",
    "\n",
    "As before, we can use histograms to get a better picture of the distribution of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df titanic histogram(:Age, xlabel=\"Age\", ylabel=\"Frequency\", bins=20, legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Density plots\n",
    "\n",
    "A density plot is similar to a histogram, but drawn with a line interpolating the bars. This makes it easier to overlay multiple plots, e.g. to compare the age distributions for passengers who did and did not survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df titanic density(:Age, groups=:Survived, lw=3, xlabel=\"Age\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@df titanic density(:Age, groups=:Sex, lw=3, xlabel=\"Age\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Let's make a new column `Child` for people under 13, based on the bump in age distrubtions. This feature could be used as one of the inputs into a decision tree or other predictive model (cf. bonus question in the assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum ChildType Child=0 Adult=1\n",
    "function classify_by_age(x)\n",
    "  if x < 13\n",
    "    return Child\n",
    "  else\n",
    "    return Adult\n",
    "  end\n",
    "end\n",
    "\n",
    "titanic[:Child] = classify_by_age.(titanic[:Age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(titanic, :Child, :Survived)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
