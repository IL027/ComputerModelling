{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Random, Plots, Statistics, PyCall\n",
    "gr()\n",
    "pydisp = pyimport(\"IPython.lib.display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IL027: Interdisciplinary Computer Modelling\n",
    "\n",
    "## Image Processing\n",
    "\n",
    "#### Laura Cooper, Warwick Mathematics Institute\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/L8/marvel.jpg\" alt=\"marvel\" style=\"width: 400px;\" align=\"right\" />\n",
    "\n",
    "<br><br>\n",
    "Image processing is a part of every day life, whether applying a filter on instagram or snapchat, watching a film or seeing an advert. The term \"to photoshop\" is even being used to describe an altered photo, after the most widely used image processing software.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/L8/ej.jpg\" alt=\"ej\" style=\"width: 400px;\" align=\"right\" />\n",
    "\n",
    "<br><br>\n",
    "Image processing is used in both art and science. Photo manipulation is an art form where the artist creates an illusion by changing and combining photographs. This is an example from Erik Johansson.\n",
    "\n",
    "Have a look at [Erik Johansson's Youtube channel](https://www.youtube.com/user/tackochgodnatt) to see how he creates his artwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images, TestImages, FFTW\n",
    "\n",
    "# Images : a collection of packages focused on image processing.\n",
    "# TestImages : a standard collection of test images. \n",
    "# FFTW: a library for fast Fourier transforms (FFTs), as well as tools useful for signal processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Image Processing in Action: Spot the Root\n",
    "\n",
    "In science image processsing is used to analysis image data in many areas. One example is looking at roots in soil. Roots can be visualised in soil using X-Ray Computed Tomorgraphy (XCT). This [video shows how XCT works](https://www.youtube.com/watch?v=o47ua5joJto&t=20s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydisp.YouTubeVideo(\"o47ua5joJto\", start=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can spot the roots in the images below, before loading the image with the roots highlighted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image without highlight\n",
    "load(\"img/L8/Root1p2um.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image with highlight\n",
    "load(\"img/L8/Root1p2umHighlight.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image without highlight\n",
    "load(\"img/L8/Root50um.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image with highlight\n",
    "load(\"img/L8/Root50umHighlight.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image without highlight\n",
    "load(\"img/L8/Root60um.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image with highlight\n",
    "load(\"img/L8/Root60umHighlight.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit [Âµ-VIS X-Ray Imaging Centre Southampton](https://www.youtube.com/channel/UCGgUXDYKG00QifY4JTq1x0w) for videos of various objects that have been in the XCT scanner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of greyscale/colour images as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "man=testimage(\"mandrill\") #Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manG=Gray.(man) #Convert to gray scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show information about images\n",
    "@show summary(man); #Summary of RGB image\n",
    "@show summary(manG); #Summary of Gray image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are arrays of type N0f8:\n",
    "\n",
    "> Normalized with 8 fractional bits, with 0 bits left for representing values higher than 1. Internally, these are represented in terms of the 8-bit unsigned integer UInt8\n",
    "\n",
    "8-bit unsigned integer have ``2^8=256`` values which are scaled between the values of 0 and 1. For the colour image there are three channels, one each for red, green and blue, and combine to make the full colour image. For the gray image there is one channel. The value relates to the intensity of the pixel with 0 being black and 1 being white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the values of individual pixels by calling them in the same way as entries in an array. A pixel from colour image has 3 values for red, green and blue. A pixel from the gray image has just one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show man[1,1]; #First pixel of RGB image\n",
    "@show manG[1,1]; #First pixel of Gray image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to grayscale is not as simple as calculating the mean of the red, green and blue channels. The values of each colour channel are weighted so that the luminance of the image is preserved.\n",
    "You can read more here: https://en.wikipedia.org/wiki/Grayscale and https://juliaimages.org/latest/arrays_colors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the mean of RGB to compare to the grayscale conversion\n",
    "manC=channelview(man) #Separate image into red, green and blue colour channels\n",
    "manA=sum.(manC[1,:,:].+manC[2,:,:].+manC[1,:,:])./3\n",
    "plot(\n",
    "    plot(manG,axis=false),\n",
    "    plot(heatmap(manA,yflip=true,fill=(true,cgrad(:grays))),axis=false,cbar=false),layout=grid(1,2),size=(800,400)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the pixels can be displayed as a histogram. This is the result for the gray scale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,counts = imhist(manG,256); #Get the number of pixels (counts) for each grey value (x)\n",
    "p1 = plot(x, counts, line=:stem,xlabel=\"Intensity\",ylabel=\"Frequency\",legend=false) #Plot histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows the number of pixels in the image for each shade of gray. There are 256 shades between the values of 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the three channels of the colour image separately. The ``channelview`` command separates the three channels into three 2D arrays and outputs them as a 3 dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "man_channels=channelview(man); #Separate colour image into three separate colour channels\n",
    "@show summary(man_channels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying each of the channels as a separate gray scale image shows the red nose of the mandrill has high intensity pixels in the red channel where as the blue areas of the face have high intensity pixels shown in the blue channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert channels to grayscale to compare intensities\n",
    "p1 = Gray.(man_channels[1,:,:]) #Red\n",
    "p2 = Gray.(man_channels[2,:,:]) #Green\n",
    "p3 = Gray.(man_channels[3,:,:]) #Blue\n",
    "plot(\n",
    "    plot(Gray.(man_channels[1,:,:]),axis=false,title=\"red\"),\n",
    "    plot(Gray.(man_channels[2,:,:]),axis=false,title=\"green\"),\n",
    "    plot(Gray.(man_channels[3,:,:]),axis=false,title=\"blue\"),\n",
    "    layout=grid(1,3),size=(900,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on we will only work with grayscale images, however the techniques can be adapted to colour images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms are one way we can visualise the information in an image. We can manipulate images to change the histogram, this can improve the appearance of the image and increase the contrast between different aspects of the image.\n",
    "\n",
    "Equalising the histogram aims to make all intensities equally probable. This increase the contrast of the image to the human eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Equalise Histogram\n",
    "hist_equalised_manG = histeq(manG, 256);\n",
    "x_eq,counts_eq = imhist(hist_equalised_manG,256);\n",
    "l = @layout (2,1)\n",
    "p1 = plot(x, counts, xlims = (0,1), line=:stem ,ylabel=\"Frequency\",legend=false)\n",
    "p2 = plot(x_eq, counts_eq, xlims = (0,1), line=:stem,xlabel=\"Intensity\",ylabel=\"Frequency\",legend=false)\n",
    "plot(p1, p2, layout = l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_equalised_manG #Display image with equalised histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising a histogram scales the range of intensities to cover all 256 values using the maximum and minimum values of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalise Histogram\n",
    "function normHist(GrayImage)\n",
    "    minim=minimum(GrayImage) #Find minimum gray scale value of image\n",
    "    maxim=maximum(GrayImage) #Find maximum gray scale value of image\n",
    "    normalised=(GrayImage.-minim)./(maxim-minim) #Normalise the image\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N=normHist(manG) #Normalise histogram of image\n",
    "Gray.(N) #Display resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compare the two histograms\n",
    "x_n,counts_n = imhist(N,256);\n",
    "l = @layout (2,1)\n",
    "p1 = plot(x, counts, xlims = (0,1), line=:stem,ylabel=\"Frequency\",legend=false);\n",
    "p2 = plot(x_n, counts_n, xlims = (0,1), line=:stem,xlabel=\"Intensity\",ylabel=\"Frequency\",legend=false);\n",
    "plot(p1, p2, layout = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can make it easier to perform certain operations of the image and ensures that the full range of intensities is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image processing segmentation is used to divide an image into different areas of interest. This can be used for combining differet images together or for analysing the size and shape of objects. \n",
    "\n",
    "Thresholding is one way to segment an image. The image is changed to a binary image where all the pixels take either the value true (1) or false (0) depending on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh_manG=manG .> 0.6; #apply a threshold between the two peaks in the original histogram\n",
    "Gray.(thresh_manG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show image as binary array\n",
    "thresh_manG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By multiplying the grayscale image with the thresholded image parts of the image are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manG_T=manG.*thresh_manG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot histogram of manG_T\n",
    "x_t,counts_t = imhist(manG_T, 256);\n",
    "plot(x_t, counts_t, xlims = (0,1), ylims=(0,6000), line=:stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All pixels below the threshold of 0.6 have been assigned to 0. We could then go on to analyse the data contained in just the upper part of the histogram.\n",
    "\n",
    "For further reading look up optimal thresholding, e.g. Otsu's method, which tries to find the optimal threshold value that separates an object from the background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying filters to an image can help to remove noise and blur an image. The ``mapwindow`` function applies a function over a window of a defined size. For example, applying a median filter on a 3x3 window means each pixel takes the median value from the surrounding 9 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lh=testimage(\"lighthouse\") #load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lhG=Gray.(lh) #convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapwindow(median, lhG, (3,3)) # apply a median function on a window of size 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapwindow(median, lhG, (31,31)) # apply a median function of a window of size 31x31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapwindow(mean, lhG, (31,31)) # apply a mean function of a window of size 31x31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapwindow(maximum, lhG, (31,31)) # apply a maximum function of a window of size 31x31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue with applying filters is what happens at the borders. There are four options:\n",
    "\n",
    ">  * replicate (repeat edge values to infinity)\n",
    ">  * circular (image edges \"wrap around\")\n",
    ">  * symmetric (the image reflects relative to a position between pixels)\n",
    ">  * reflect (the image reflects relative to the edge itself)\n",
    "\n",
    "The default option is ``replicate``.\n",
    "\n",
    "A Gaussian filter can be used to blur an image to remove noise and details. In 1D a Gaussian function looks like a bell curve. It is similar to applying a median filter but rather than giving all the pixels in the window the same weight, or importance, when calculating the average, the Gaussian filter gives more weight to the pixels closest to the centre of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fs = 100;           # Sampling frequency\n",
    "t = -0.5:1/Fs:0.5;  # Time vector \n",
    "L = length(t);      # Signal length\n",
    "Gauss = 1/(4*sqrt(2*pi*0.1))*(exp.(-t.^2/(2*0.1^2))); #Gaussian signal assuming mean at 0 and standard deviation 0.1\n",
    "plot(t,Gauss,xlabel=\"x\",ylabel=\"G(x)\") # 1D Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lhG_G=imfilter(lhG, Kernel.gaussian(5)) #apply gaussian filter to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian filter has the effect of 'smoothing' the histogram. The Gaussian filter is an example of a low pass filter (further explaination can be found [here](https://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm))  The effect is to remove high spatial frequency components from the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, counts=imhist(lhG);\n",
    "x_g, counts_g=imhist(lhG_G);\n",
    "l = @layout (2,1)\n",
    "p1 = plot(x, counts, xlims = (0,1), ylims = (0,2.4e4), line=:stem, ylabel=\"Freqency\",legend=false)\n",
    "p2 = plot(x_g, counts_g, xlims = (0,1), ylims = (0,2.4e4), line=:stem, xlabel=\"Intensity\",ylabel=\"Freqency\",legend=false)\n",
    "plot(p1, p2, layout = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen Image\n",
    "Most basic image processing software offers an option to sharpen an image. To do this we create a kernel by subtracting a \"blurring\" kernel. We make use of ```cld(x, y)``` which returns the smallest integer larger than or equal to x/y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sharpenK(Kernel)\n",
    "m,n=size(Kernel)\n",
    "sharp=zeros(m,n) #Create zero array\n",
    "sharp[cld(m,2),cld(n,2)]=sharp[cld(m,2),cld(n,2)]+2 #Add one to central pixel, \n",
    "sharp=sharp.-collect(Kernel) #Subtract the Gaussian (smoothing) kernel, collect replaces OffsetArray with Array\n",
    "    return sharp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpenK(Kernel.gaussian(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhG_S=imfilter(lhG, sharpenK(Kernel.gaussian(5))) #apply gaussian filter to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g, counts_g=imhist(lhG_S);\n",
    "l = @layout (2,1)\n",
    "p1 = plot(x, counts, xlims = (0,1), ylims = (0,2.4e4), line=:stem, ylabel=\"Freqency\",legend=false)\n",
    "p2 = plot(x_g, counts_g, xlims = (0,1), ylims = (0,2.4e4), line=:stem, xlabel=\"Intensity\",ylabel=\"Freqency\",legend=false)\n",
    "plot(p1, p2, layout = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform maps a signal to its component freqencies. Think about sound: Bass sounds (low pitch) come from low-freqency components and Treble sounds (high pitch) come from high-frequency components\n",
    "* Remove hissing noise on a recording by removing the high frequecies\n",
    "* Make next door party music by removing all high frequecies\n",
    "\n",
    "We can create a signal, you can imagine its a recording picked up by a microphone. Adding some noise to the signal can be thought of as background sounds that were picked up during the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a signal with some noise\n",
    "Fs=1000; #Sample freqency\n",
    "L=1500 # Length of signal\n",
    "t=(0:L-1)/Fs # Time Vector\n",
    "Hz1=20; #Signal 1\n",
    "Hz2=80; #Signal 2\n",
    "f=sin.(2*pi*Hz1*t)+sin.(2*pi*Hz2*t)+randn(Float64, size(t))\n",
    "plot(1000*t,f, xlabel=\"Time\", ylabel=\"Signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to see the two signals in the above plot. Applying a Fourier transform to this signal shows the two signals clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y=fft(f); # Fourier transform of function\n",
    "P2=abs.(Y/L) #2 sided spectrum\n",
    "P1=P2[1:(750+1)]; #1 sided spectrum\n",
    "P1[2:end-1]=2*P1[2:end-1];\n",
    "fd=Fs*(0:(L/2))/L; #Freqency fomain\n",
    "l=@layout (2,1)\n",
    "p1=plot(fd, P1)\n",
    "p2=plot(fd, P1, xlims = (0,100),xlabel=\"Frequency\")\n",
    "plot(p1, p2, layout = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lena=testimage(\"lena_gray_256\"); #Open an image\n",
    "lenaG=Gray.(lena)#+0.5*Noise\n",
    "rows, cols=size(lenaG)\n",
    "#Add some noise bands to the image\n",
    "x=0:rows-1\n",
    "Noise=cos.(pi*x/16).*(ones(rows,cols))\n",
    "im_noise=Float64.(lenaG)+0.5*Noise\n",
    "Gray.(im_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how adding this noise effects the histogram of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_n, counts_n=imhist(im_noise);\n",
    "plot(x_n, counts_n, xlims = (0,1), line=:stem, xlabel=\"Intensity\",ylabel=\"Freqency\",legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to see what's noise and what's the original image from the histogram. We can apply a Fourier transform to the noisy image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows, cols=size(im_noise)\n",
    "Y=fft(im_noise);\n",
    "heatmap(fftshift(log.(abs.(Y))),fill=cgrad(:grays,scale=:log), clims=(-2, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot of the Fourier transform above there are two white points near the centre of the image. These spots in the freqency domain show the noise - like the spikes in the 1D example above. The function below removes the two spots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#low pass filter\n",
    "filterlow=fftshift(Y[:,:])\n",
    "for y in 1:rows\n",
    "    for x in 1:cols\n",
    "        if (y-rows/2-2)^2+(x-cols/2-9)^2-2^2>=0 && (y-rows/2-1)^2+(x-cols/2+8)^2-2^2>=0\n",
    "        else\n",
    "            filterlow[x,y]=1e-3\n",
    "        end\n",
    "    end\n",
    "end\n",
    "heatmap((log.(abs.(filterlow))),fill=cgrad(:grays,scale=:log), clims=(-2, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can apply the inverse of the Fourier transform to get the original image back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=ifft(filterlow)\n",
    "Xn=Gray.(abs.(X))\n",
    "Gray.(normHist(Xn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about using Fourier Transforms for image processing can be found here: https://www.cs.unm.edu/~brayer/vision/fourier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection is another method of segmentation. It is used to highlight the edges of the image. Edges in images are defined where there are steep gradients. The gradient can be found by calculating the derivative. Since images are discrete arrays the derivative needs to be approximated. The most basic method is finite difference. If $Q$ is our original image and $P$ is our new image with edges detected the gradients can be approximated as,\n",
    "\\begin{equation}\n",
    "P_{ij}=|2Q_{ij}-Q_{ij-1}-Q_{i-1j}|\n",
    "\\end{equation}\n",
    "where $i$ and $j$ are pixels in the $x$ and $y$ directions, respectively. This function calculates the value of the new image by subtracting the values of the neighbouring pixels from the left and below. The larger the difference between the current pixel and the neighbouring pixels, the more likely this is to be an edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera=testimage(\"cameraman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Edge detection method 1 - finite difference\n",
    "newpic=zero(camera)\n",
    "rows, cols = size(camera)\n",
    "for x=2:rows-2\n",
    "    for y=2:cols-2\n",
    "        newpic[x,y]=abs(2*camera[x,y]-camera[x,y+1]-camera[x-1,y])\n",
    "    end\n",
    "end\n",
    "newpic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method is applying a Sobel filter. This is similar to finite difference but uses a mask of 8 pixels weighted around a central point. In image processing this mask is known as a kernel and the process of applying the kernel to the image is a convolution. The Sobel filter uses two kernels, $\\pmb{G}_x$ and $\\pmb{G}_y$\n",
    "\n",
    "\\begin{equation}\n",
    "\\pmb{G}_x=\\begin{bmatrix} -1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1 \\end{bmatrix}\\ \\ \\ \\text{and}\\ \\ \\ \n",
    "\\pmb{G}_y=\\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +2 & +1 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Note that $\\pmb{G}_x$ is the transpose of $\\pmb{G}_y$. These kernels allow the pixels on both the left and the right (or the one above and the one under) to be compared to the central pixel. The command ``imfilter`` can be used to apply the defined kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sobel\n",
    "sk=centered([1 0 -1; 2 0 -2; 1 0 -1]); #Define kernel, centered tells Julia the origin of the kernel is at the centre of the Array\n",
    "sobel_x=imfilter(camera,sk); #Apply kernel in x direction\n",
    "grad=imfilter(sobel_x, sk')  #Apply kernel in y direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an inbuild sobel kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "builtin=64*(imfilter(camera,Kernel.sobel())) #Mulitply by 64 to increase contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more advance edge detection method is ``canny``. This combines the Gaussian filter with the Sobel edge detection kernel. This helps to remove the noise. More information can be found https://en.wikipedia.org/wiki/Canny_edge_detector and https://juliaimages.org/latest/function_reference/#Images.canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "canny_edges=canny(camera, (Percentile(95), Percentile(40))) #Apply Canny filter, apply bounds to remove 'weak' edges\n",
    "Gray.(canny_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply some transforms to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lake=testimage(\"lake_color\") #Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lake_rot=imrotate(lake,pi/2) #Rotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_rot=lake' #Rotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lake_rot=imrotate(lake,pi/4) #Rotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lake_re=imresize(lake,ratio=1/2) #Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lake_c=lake[350:end-50,280:end-150] #Crop image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "It is useful to be able to gain quantiative information from an image. To do this, we start by segmenting the image - separating out the objects of interest from the rest of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rice=load(\"img/L8/rice.png\") #Load image\n",
    "rice=rice[1:end-100,:] #Crop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate and plot histogram\n",
    "x_r, counts_r=imhist(rice);\n",
    "plot(x_r, counts_r, xlims = (0,1), line=:stem, ylabel=\"Freqency\",legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two spikes can be seen in the histogram. The one on the left represents the background and the one of the right represents the grains of rice. So we can apply a threshold to segment the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh_r=rice .> 0.6 #apply a threshold\n",
    "Gray.(thresh_r) #Display the resulting segmented image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```label_components``` allows us to count how many objects there are and also colour all the objects different colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels=label_components(thresh_r) #Labels each object separately\n",
    "maximum(labels) #returns maximum label number, equal to number of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to generate a random colour for each label\n",
    "function get_random_color(seed)\n",
    "    Random.seed!(seed)\n",
    "    rand(RGB{N0f8})\n",
    "end\n",
    "#plot the multicoloured rice grains\n",
    "plot(map(i->get_random_color(i), labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are some partial grains around the edges and some odd pixels due to noise in the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove small rice grains - probably noise or partial grains\n",
    "component_lengths(labels) #returns area for each label\n",
    "labels_list=0:maximum(labels)\n",
    "mask=labels_list[component_lengths(labels).>100] #Only keep rice grains with area greater than 100\n",
    "new_labels=zeros(Int64,size(labels))\n",
    "for j=1:length(mask)\n",
    "    new_labels += ((labels.==mask[j]).*(j-1)) #Create new label array with only larger grains\n",
    "end\n",
    "@show maximum(new_labels)\n",
    "plot(map(i->get_random_color(i), new_labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the  of the rice grains are joined together. They can be separated using [morphological operations](https://juliaimages.org/latest/function_reference/#ImageMorphology.dilate)  like ```erode``` and ```dilate```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use erode to separate grains. removes (remove 1 element around edge) - also can help remove noise\n",
    "#Note that sometimes it is necessary to erode the image more than once\n",
    "etr=erode(thresh_r)\n",
    "Gray.(etr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relabel separated rice grains\n",
    "e_labels=label_components(etr)\n",
    "plot(map(i->get_random_color(i), e_labels) )\n",
    "maximum(e_labels)\n",
    "Gray.(dilate(e_labels.>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labels=zeros(Int64,size(e_labels))\n",
    "for j=1:maximum(e_labels)\n",
    "    d_labels=d_labels .+ (dilate(e_labels.==j))*(j-1) #dilate is opposite of erode, apply to each label separately\n",
    "end\n",
    "#replace overlaps with background colour to separate.\n",
    "d_labels[d_labels.>maximum(e_labels)].=0 #Overlaps identified values over the maximum label calculated on eroded image\n",
    "plot(map(i->get_random_color(i), d_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extension: can you find the smallest and largest grains of rice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to see how close the rice grains are to each other using ```distance_transform```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find distance between grains of rice\n",
    "F=feature_transform(d_labels.>0)#finding the closest \"feature\" for each location\n",
    "D=distance_transform(F) #Compute the distance transform where each element represents a \"feature\" location. Specifically, D[i] is the distance between a location and a feature.\n",
    "heatmap(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Art Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image processing can be used for both art and science. Above, we have shown how image processing can be use to gain quantitative data. Now we will use similar techniques to create artwork. I have chosen to create a piece of art based on Drawing hands by M. C. Escher: https://en.wikipedia.org/wiki/Drawing_Hands.\n",
    "\n",
    "The aspects of the piece I aim to recreate are:\n",
    "- Grayscale\n",
    "- Outlined sleeves and realistic hands\n",
    "- Hands in a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm=load(\"img/L8/Arm.JPG\") #Load image\n",
    "arm_c=Gray.(arm[:,30:end-30]) #Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and plot histogram\n",
    "counts_a, x_a=imhist(arm_c); \n",
    "plot(counts_a, x_a, xlims = (0,1), line=:stem, ylabel=\"Freqency\",legend=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use histogram to choose threshold\n",
    "arm_t=Gray.(arm_c).<0.58 #Foreground\n",
    "back=Gray.(arm_c).>0.58 #Background\n",
    "arm_seg=Gray.(arm_t.*arm_c) #Use thresholded foreground to separate arm from background\n",
    "arm_seg[arm_seg .== 0].=1 #Set background color to white\n",
    "arm_canny_edges=canny(Gray.(arm_c), (Percentile(99), Percentile(5))) #Find edges of arm\n",
    "dil_arm=(dilate(dilate(arm_canny_edges))) #Dilate to make edge appear thicker, note we dilate twice\n",
    "armedge=Gray.(1 .- dil_arm) #Create inverse of edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_outline=Gray.((1 .- arm_seg).*armedge) #Outline the inverse of the arm\n",
    "arm_t[1:80,end-26:end].=0 #Black out corner of arm\n",
    "arm_outback=arm_outline+back #Add white background to inverted arm\n",
    "arm_f=[arm_outback[1:end-100,:];arm_seg[end-100:end,:]] #Add the outlined arm to segmented hand\n",
    "#Take a subsection to make black so that image shows when overlayed\n",
    "arm_sub=arm_f[:,end-26:end] \n",
    "arm_sub[arm_sub.==1].=0\n",
    "arm_final=hcat(arm_f[:,1:end-26],arm_sub)\n",
    "Gray.(arm_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotate thresholded arm\n",
    "p2=imrotate(arm_t,pi)\n",
    "p2[isnan.(p2).==1].=0 #remove nan values\n",
    "m, n=size(arm_t)\n",
    "l=hcat(arm_final,zeros(m+1,n-26)) #Add zeros to right increase size of image\n",
    "r=hcat(zeros(m+2,n-26),p2) #Add zeros to left of rotated arm\n",
    "left=(l .- r[2:end,2:end]) #Subtract thresholded arm from outlined arm\n",
    "left[left.<=0].=0 #Remove some noise\n",
    "Gray.(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right=imrotate(left,pi) #rotate\n",
    "full=left .+ right[2:end,2:end] #Add original and rotated images together to make circling arms\n",
    "#Remove black stripe from centre\n",
    "mid=full[:,181-26:182+1];\n",
    "mid[mid.<=0.05].=1\n",
    "#Combine images to create final piece\n",
    "final=hcat(full[:,1:181-26],mid,full[:,182:end])\n",
    "Gray.(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on using Julia for image processing: \n",
    "\n",
    "- https://juliaimages.org/latest/quickstart/ \n",
    "- https://juliaimages.org/latest/function_reference/\n",
    "\n",
    "Benchmark image collections are used by researchers to develop and evaluate their algorithms for image processing tasks. Here are a some of examples: \n",
    "\n",
    "- https://data.broadinstitute.org/bbbc/ \n",
    "- https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/\n",
    "\n",
    "There are also many image datasets shared online that can be used for research or to appreciate as art\n",
    "- https://earthobservatory.nasa.gov/images \n",
    "- https://www.nasa.gov/mission_pages/hubble/multimedia/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
