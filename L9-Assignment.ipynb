{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f06422a34942d1d1825852763bba46f",
     "grade": false,
     "grade_id": "cell-cd8b4f380ddbb5b7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa0b5ccfc25ed1a82a7ec8ff1be02b71",
     "grade": false,
     "grade_id": "cell-f0f7b1d4feeb3ec9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 9.1 Understanding Model Parameters (Multiclass Logistic Regression and Multilayer Perceptron) (30%)\n",
    "\n",
    "In this section, you will examine the trained MNIST models from the Week 9 lecture.\n",
    "\n",
    "9.1.1.) What is the total number of pixels in each MNIST input image?\n",
    "\n",
    "For the **multiclass logistic regression model** in Week 9:\n",
    "\n",
    "9.1.2.a) How many total input values are there to the model? (Understand why.)\n",
    "\n",
    "9.1.2.b) How many total output values? (Understand why.)\n",
    "\n",
    "9.1.2.c) How many total parameters are there to the model? (Note that the parameters object `w` is a two-element array including both the large *weight* matrix and the smaller *bias* vector, which together compose the parameters of the model.)\n",
    "\n",
    "For the **multilayer perceptron model**:\n",
    "\n",
    "9.1.3.a) What is the number of input values to the input layer?\n",
    "\n",
    "9.1.3.b) What is the number of output values to the input layer (and hence the number of inputs to the first hidden layer)?\n",
    "\n",
    "9.1.3.c)  What is the number of output values to the first hidden layer (and hence the number of input values to the second hidden layer)?\n",
    "\n",
    "9.1.3.d)  What is the number of output values to the second hidden layer?\n",
    "\n",
    "9.1.3.e) How many total parameters are there, including the weight matrices and bias vectors for all layers? (Note that in this model the parameters array `w` has more than two elements. Understand why.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "608c1bce75890992eaa9f5cc56f1bd50",
     "grade": false,
     "grade_id": "cell-9a7a1e5d2a49e71d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# PLEASE REPLACE THE NUMBERS WITH THE CORRECT SOLUTIONS\n",
    "solution1 = Dict(\n",
    "   \"9.1.1\" => 234,\n",
    " \"9.1.2.a\" => 432,\n",
    " \"9.1.2.b\" => 56,\n",
    " \"9.1.2.c\" => 999,\n",
    " \"9.1.3.a\" => 777,\n",
    " \"9.1.3.b\" => 555,\n",
    " \"9.1.4.c\" => 123,\n",
    " \"9.1.4.d\" => 21, \n",
    " \"9.1.4.e\" => 321654\n",
    ")\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eafa5824c1a8fd490444515d1d400ece",
     "grade": true,
     "grade_id": "cell-f679be5d0c3045ff",
     "locked": true,
     "points": 14,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1393b711c8f614cb7c3016f5b00b96d",
     "grade": false,
     "grade_id": "cell-8eb147d7142b25cb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 9.2 Understanding Model Parameters (Convolutional Model) (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d617b4e8d175bc97b325dc6242350495",
     "grade": false,
     "grade_id": "cell-3e0153cdba0fc33c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this section, you will examine the trained MNIST model from the Week 10 lecture.\n",
    "\n",
    "For the model as defined by the `initweights` function (see also the corresponding `predict` function which shows how to get to a prediction given the weights and an input), determine:\n",
    "\n",
    "9.2.1. How many weights are in the first convolutional layer? (Not including the bias vector)\n",
    "9.2.2. How many weights are in the second convolutional layer? (Not including the bias vector)\n",
    "9.2.3. How many weights are in the next fully-connected layer? (Not including the bias vector)\n",
    "9.2.4. How many weights are in the final layer? (Not including the bias vector)\n",
    "9.2.5. How many weights are in the entire set of parameters (including all bias vectors)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "751b9d83ef5ebf47152af3aa43e49d96",
     "grade": false,
     "grade_id": "cell-f2c49b18b7bdd2e2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# PLEASE REPLACE THE NUMBERS WITH THE CORRECT SOLUTIONS\n",
    "solution2 = Dict( \n",
    "    \"9.2.1\" => 123,\n",
    "    \"9.2.2\" => 25000,\n",
    "    \"9.2.3\" => 100000,\n",
    "    \"9.2.4\" => 1001,\n",
    "    \"9.2.5\" => 400000\n",
    ")\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b1f4d6dad9f57840d35f3044a5bc479",
     "grade": true,
     "grade_id": "cell-d70616f5acc4ac16",
     "locked": true,
     "points": 30,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8cd8c9f24c5c34b5d26a7643d471f2b4",
     "grade": false,
     "grade_id": "cell-1c42b82e11170c6b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 9.3. Examining Incorrect Predictions (Convolutional Model) (40%)\n",
    "\n",
    "In this section you will answer the question of which handwritten digits are most often misclassified by this convolutional neural network model.\n",
    "\n",
    "First, make sure that directly before you train your convolutional model (for the default of 10 epochs), you set the random-number-generator seed to (the arbitrary value) 1234, like so:\n",
    "\n",
    "`srand(1234);`\n",
    "\n",
    "This way, the training process should be equivalent for everyone (but perhaps it won't be! We'll check.)\n",
    "\n",
    "Once you have trained your model, to help your understanding, write some code to display an arbitrary MNIST digit from the test dataset `dtst` using the supplied `mnistview()` function. (Hint: you can use the `collect()` and `enumerate()` functions to transform an iterable object like `dtst` to an indexable array of minibatches, each of which contain 10 images and 10 associated integer labels. Also, you can use the function `convert(UInt32, x)` where x is some other kind of numerical object â€” this will be useful because the integer label of the test data's digit is stored as a less-user-friendly `UInt8` type.\n",
    "\n",
    "In general, you will want to use the built-in functions like `typeof()` and `length()` to determine how to interrogate the `dtst` object and break it up into minibatches and then break those minibatches up into MNIST images and their corresponding human-coded integer values.\n",
    "\n",
    "Once you have a sense of how the MNIST digits and their labels can be interrogated, write code to loop over the test dataset, manually doing predictions on each minibatch (using `predict(params, image)` and comparing the predicted values to the supplied integer labels. Your goal is to find out which digit is most frequently misclassified, so as you go through each minibatch, keep track of when the predicted value did not correspond with the actual value of the label in the test data.\n",
    "\n",
    "9.3.1. Which two digits  are most likely to be misclassified by the trained model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bc2680aacf72d97694cc09594212612d",
     "grade": false,
     "grade_id": "cell-075845bab0a05496",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# PLEASE REPLACE THE TWO NUMBERS WITH THE CORRECT DIGITS TO SOLVE THIS QUESTION \n",
    "solution3 = [6, 15]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3d54f31a59453940608ae14f13d40ae4",
     "grade": true,
     "grade_id": "cell-042b589fb6772199",
     "locked": true,
     "points": 40,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
